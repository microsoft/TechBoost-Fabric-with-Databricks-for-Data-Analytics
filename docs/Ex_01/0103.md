### Task 1.3: Data Ingestion
There are multiple ways to ingest data in Lakehouse.
### Method 1-Using Data Pipelines/Data Flow ‘No Code-Low Code experience’

1. In Power BI tab,while you are in the ContosoSales@lab.LabInstance.Id workspace, click the **left bottom icon** and click on **Data Engineering**.

	![DE.](instructions240153/task-1.3.1.png)


2. In Data Engineering, select **Data pipeline (Preview)**.

	![Pipeline.](instructions240153/task-1.3.2.png)

3. In the pop-up, type the pipeline name,by clicking on +++**Azure SQL DB Pipeline**+++ and click on the **Create** button.

4. Click on **Copy data**.

5. In the pop-up, scroll down through the resources, click on **Azure SQL Database** and then click on the **Next** button.

6. Select the **Create new connection** radio button, if not selected.


7. In the **Server** field paste the value and by clicking on +++**@lab.Variable(sqlEndpoint)**+++ and in the **Database** field by clicking on +++**SalesDb**+++.


8. Scroll down and select **Basic** for Authentication kind, click on +++labsqladmin+++ as the Username, +++Smoothie@2023+++ as the Password, keep **Use encrypted connection** check box **on/checked** and finally click on the **Next** button.

	>**Note:** Close any pop-up that you see and wait for the connection to be created.

9. **Select** the 'Existing tables' radio button, **click** on the checkbox for the **First Table** below the Select all option, and then **click** on the 'Next' button.

10. Scroll down and click on **Lakehouse** and then click on the **Next** button.

11. Click on the **Existing Lakehouse** radio button, click on the **dropdown**, select **lakehouseBronze** and then click on the **Next** button.

12. Select the **Load to new table** radio button, click on the checkbox beside **Source** and then click on **Next**.

13. Click on **Save + Run**.

14. Click on the **Notifications Icon** at top right of the screen, select **Notifications**.

15. Verify the **Running status** of the pipeline.

	>**Note:** Please wait for the pipeline to execute. If the notification continues to say running after 10 minutes, check the monitoring hub for a "succeeded" status.
	>!IMAGE[0faouzwm.png](instructions249094/0faouzwm.png)

16. Once the status shows **Run Succeeded**, your data has been transferred from Azure SQL Database to Lakehouse.

17. Similarly you can get data into the lakehouses using pipelines from various other sources like Snowflake, Dataverse, etc.


### Method 2-Using the ‘OneLake Shortcuts’ option from external data sources

This is something exciting! You will see how easy it is to create **shortcuts** without actually moving the data. That is the power of OneLake! In this exercise you will easily ingest the curated marketing data as well as product reviews data from ADLS Gen2. Let's see how!

1. In **Power BI** tab, click **Workspaces** and select the ContosoSales@lab.LabInstance.Id workspace.


2. In the ContosoSales@lab.LabInstance.Id workspace, click on the **lakehouseBronze** Lakehouse.

	>**Note:** There will be 3 options for lakehouseBronze, namely Lakehouse, Dataset (default) and SQL endpoint. Make sure to select the Lakehouse option.
	>!IMAGE[ub6haecs.png](instructions249094/ub6haecs.png)


3. Right-click on **Files** in the left explorer.

4. Click on **New shortcut**.

5. In the pop-up window, under **External sources**, select the **Azure Data Lake Storage Gen2** source.

	>**Note:** Wait for the screen to load.

6. We need to enter the connection details for the ADLS Gen2 shortcut. For this, we need to get the details from the Storage Account resource.

7. In the URL field above, paste the endpoint by clicking on  +++**https://storage@lab.LabInstance.Id.dfs.core.windows.net/**+++ **URL** field.

8. In the **Authentication kind** dropdown, select **Account Key**.

9. Paste the account key by clicking on +++**@lab.Variable(storageAccountKey)**+++.

10. Click on **Next**.

11. Under **Shortcut Name**, enter +++**data**+++.

12. Under **Sub Path**, type by clickiing on +++**/adlsfabricshortcut**+++.

13. Click on the **Create** button.


Litware Inc. has curated marketing data and sales data processed by Azure Databricks and stored in the gold layer in ADLS Gen2. You can easily create a shortcut in Microsoft Fabric without moving this data. **We will now create another shortcut for Litware Inc. data.**

14. Right-click on **Files** in the left explorer.

15. Click on **New shortcut**.

16. In the pop-up window, under **External sources**, select the **Azure Data Lake Storage Gen2** source.

	>**Note:** Wait for the screen to load.

17. In the URL field above, paste the endpoint under the **URL** field by clicking on +++**https://storage@lab.LabInstance.Id.dfs.core.windows.net/**+++

	>**Note:** The details entered earlier will be auto fetched. If not, the previous shortcut steps.

18. In the **Authentication kind** dropdown, select **Account Key**.

19. Paste the account key by clicking on +++**@lab.Variable(storageAccountKey)**+++.

	>**Note:** Wait for the storage AccountKey to be field automatically.

20. Click on **Next**.

21. Under **Shortcut Name**, type by clicking on +++**sales-transaction-litware**+++.

22. Under **Sub Path**, type by click on +++**/bronzeshortcutdata**+++.

23. Click on the **Create** button.
